


sudo yum install htop java-11 -y
sudo yum groupinstall "Development Tools" -y
mkdir -p ${HOME?}/git && git -C ${HOME?}/git clone https://github.com/percent25/awscat.git



export LOGGING_LEVEL_HELPERS=DEBUG
export LOGGING_LEVEL_IO_GITHUB_AWSCAT=DEBUG

export LOGGING_LEVEL_HELPERS=TRACE
export LOGGING_LEVEL_IO_GITHUB_AWSCAT=TRACE

rrizun@rrizuns-MacBook-Air dynamocat % LOGGING_LEVEL_IO_GITHUB_AWSCAT=DEBUG java -jar target/awscat-0.0.1-SNAPSHOT.jar dynamo:MyTableOnDemand

spel downsides
 1. no comma expressions
 1. weird inline array syntax
 1. {:} is immutable!! wtf?

javascript downsides
 1. while (true)

spel ?: vs js ??
arrays: spel {1,2,3} vs js [1,2,3]
objects: spel {:} is immutable!! wtf?

======================================================================
OPEN
======================================================================

 - need to wait for graceful shutdown in receivers: AwsKinesisReceiver



 - generic plugin <Options> 

 - kinesis plugins

 - uuid source.. i.e, stream of uuid json strings
 
 
 
 - dynamo input plugin: limit is not what is intuitively limit.. it is scan limit, not overall limit



 - SystemInPlugin: can't cycle stdin



 - dynamo input plugin read-ahead ??

 

--limiter=redis://blahblahblah
 - really a dynamo option.. wcu=2000,limiter=redis://localhost



dynamo reader/writer
 - if preAcquire < consumedCapacityUnits then post-acquire the difference!!



s3 output plugin
 - embed segment/totalSegments/startElement/finishElement in object names??


 
github actions?



concurrency
 vs
parallelism



[ssm-user@ip-10-0-197-2 awscat]$ ./x queue.json dynamo:OnDemand,wcu=20000
 - ^^^ this is pretty choppy on .8xlarge.. queue.json was 9GB
java.util.concurrent.ExecutionException: software.amazon.awssdk.core.exception.SdkClientException: Unable to execute HTTP request: Acquire operation took longer than the configured maximum time. This indicates that a request cannot get a connection from the pool within the specified maximum time. This can be due to high request rate.
Consider taking any of the following actions to mitigate the issue: increase max connections, increase acquire timeout, or slowing the request rate.
Increasing the max connections can increase client throughput (unless the network interface is already fully utilized), but can eventually start to hit operation system limitations on the number of file descriptors used by the process. If you already are fully utilizing your network interface or cannot further increase your connection count, increasing the acquire timeout gives extra time for requests to acquire a connection before timing out. If the connections doesn't free up, the subsequent requests will still timeout.
If the above mechanisms are not able to fix the issue, try smoothing out your requests so that large traffic bursts cannot overload the client, being more efficient with the number of times you need to call AWS, or by increasing the number of hosts sending requests.
 - ah.. source is SystemIn, so, high concurrency, large batch.. target is dynamo writer.. small batch = 25 hmmm...
 - "concurrency" for dynamoWriter ?!? ?!? ?!?
 - ### THIS IS CHOPPY BECAUSE THERE IS NO DYNAMO INPUT PLUGIN 'READ AHEAD'



dynamoOutputPlugin: handle unprocessedItems.. dlq or retry?



at start, have plugins report their desired/reported [50%]
Sat Mar 20 10:00:26 PDT 2021 ctor
Sat Mar 20 10:00:27 PDT 2021 run
Sat Mar 20 10:00:27 PDT 2021 inputPlugin SystemInPlugin{in=java.io.BufferedInputStream@53976f5c, concurrency=4}
Sat Mar 20 10:00:27 PDT 2021 outputPlugin io.github.awscat.SystemOutPluginProvider$$Lambda$383/0x0000000800d21538@2bfc268b
Sat Mar 20 10:00:27 PDT 2021 start mtu -1
Sat Mar 20 10:01:57 PDT 2021 ctor
Sat Mar 20 10:01:57 PDT 2021 run
Sat Mar 20 10:01:57 PDT 2021 inputPlugin SystemInPlugin{in=java.io.BufferedInputStream@be35cd9, concurrency=4}
Sat Mar 20 10:01:57 PDT 2021 outputPlugin SystemOutPluginProvider{base=-, options={"append":false}}
Sat Mar 20 10:01:57 PDT 2021 start mtu -1



s3outputplugin
 - https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DataExport.Output.html
 - https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.LowLevelAPI.html
  - { Key: {...}} -or- { Item: {...} } -also- { Count:1, Items: [{"foo":{"S":"bar"}}] }
 - https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html#Scan.FilterExpression


[#1] go back to individual JsonElement in main loop.. this is for "dlq" in the main loop
 - this'll also help with the thundering herd impulse problem..
          awscat.jar dynamo:MyTableOnDemand dynamo:MyTableOnDemand,wcu=500
  - update: maybe don't need to go this far.. would not be able to leverage 'natural' source batching, e.g., sqs receiveMessage, dynamo scan, etc..
  - InputPlugins deliver in terms of their natural batching.. outputPlugins can write individual JsonElement objects in terms of their natural batching



dynamo resume state



print unrecognized options



Zero or more output targets? (i.e., tee)



gzip compression???



======================================================================
CLOSED
======================================================================

[ssm-user@ip-10-0-131-97 dynamocat]$ ./dynamocat.jar out.txt arn:aws:sns:us-east-1:343892718819:Dev-Myservice-MyTopic86869434-15ADVC9V4NAHB

rrizun@rrizuns-MacBook-Air dynamocat % ./dynamocat.jar xaa arn:aws:sns:us-east-1:343892718819:Dev-Myservice-MyTopic86869434-15ADVC9V4NAHB

main.helpers.ConcatenatedJsonWriter@6d1310f6 ctor
main.plugins.AwsTopicOutputPlugin@3228d990 ctor
main.plugins.AwsTopicOutputPlugin@3228d990 write 1000
main.helpers.ConcatenatedJsonWriter@6d1310f6 flush
main.Main$$EnhancerBySpringCGLIB$$ac85f331@52e7a6b2 in 102355 out 95000 [read]
main.helpers.ConcatenatedJsonWriter@50b8ae8d ctor
main.plugins.AwsTopicOutputPlugin@255990cc ctor
main.plugins.AwsTopicOutputPlugin@255990cc write 355
main.helpers.ConcatenatedJsonWriter@50b8ae8d flush
main.Main$$EnhancerBySpringCGLIB$$ac85f331@52e7a6b2 in 102355 out 96000 [write]
main.Main$$EnhancerBySpringCGLIB$$ac85f331@52e7a6b2 in 102355 out 97000 [write]
main.Main$$EnhancerBySpringCGLIB$$ac85f331@52e7a6b2 input.read().get();222



dynamo delete [done]

logging.. .debug(..) not working??

input plugins: limit?

DynamoInputPlugin
  - ,keys=true
  - render key first ?

custom.script

dlq filename: embed timestamp in filename

//###BADIDEA
//###BADIDEA
//###BADIDEA
dynamo: from aws sdk javascript AWS.DynamoDB.Converter.marshall/unmarshall ? i.e., parse/render dynamo records?
 - https://github.com/aws/aws-sdk-js-v3/tree/main/lib/lib-dynamodb use graalvm/js ?
 - https://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/dynamodb-example-dynamodb-utilities.html
//###BADIDEA
//###BADIDEA
//###BADIDEA

dynamo scan: permits queue necessary?

DLQ: log to dlq pre-transform or post-transform?
 - ans: pre-transform.. why? because there could've been an error during transform so therefore u wouldn't have the post-transform



table to topic not working??
 - works on macbook air w/default c=4
 - does not work on c5.8xlarge w/c=32.. didn't seem to work w/c=1 either ?!?
 - when source table is limit=200 then it works
 - typical source table batch size is 6000 or so2021-03-19 14:59:15,375 [DynamoInputPlugin] doSegment 0 
2021-03-19 14:59:15,386 [DynamoInputPlugin] doSegment 0 ScanRequest(TableName=MyTableOnDemand, TotalSegments=1, Segment=0) 
2021-03-19 14:59:15,663 [DynamoInputPlugin] doSegment 0 6483 
2021-03-19 14:59:17,877 [Main$$EnhancerBySpringCGLIB$$6a7d9466] listener 6483 
 - looks like concatenatedJsonWriter/awsTopicWriter cannot handle 6000ish at-a-time
 - continuing investigation
 - looks like it seizes up at 1829
 Fri Mar 19 15:19:44 UTC 2021 Progress{"request":1829,"success":0,"failure":0}
2021-03-19 15:19:44,162 [ConcatenatedJsonWriterOutputPlugin] write {"id":{"s":"0a27fc83-b794-4158-8d8f-e268637d679c"},"val1":{"s":"651cca41-6bda-41b4-8c53-5919d5c3ec87"},"val2":{"s":"3dea400e-adb9-4b83-a875-23b408ddbeca"},"val3":{"s":"8ac42862-b89a-4ce5-ae8a-146ea912a674"}} 
 - so in other words, right at the first batch.. so its a len>mtu() cross over boundary condition

2021-03-19 15:50:16,609 [DynamoInputPlugin] doSegment 30 
2021-03-19 15:50:16,609 [DynamoInputPlugin] doSegment 30 ScanRequest(TableName=MyTableOnDemand, TotalSegments=32, Segment=30) 
2021-03-19 15:50:16,610 [DynamoInputPlugin] doSegment 31 
2021-03-19 15:50:16,610 [DynamoInputPlugin] doSegment 31 ScanRequest(TableName=MyTableOnDemand, TotalSegments=32, Segment=31) 
2021-03-19 15:50:17,117 [DynamoInputPlugin] doSegment 14 5948 
2021-03-19 15:50:19,431 [Main$$EnhancerBySpringCGLIB$$6a7d9466] listener 5948 
2021-03-19 15:50:19,447 [ConcatenatedJsonWriter] ctor 
2021-03-19 15:50:19,448 [ConcatenatedJsonWriterOutputPlugin] ctor 
2021-03-19 15:50:19,641 [ConcatenatedJsonWriter] flush 262038 
2021-03-19 15:50:19,642 [ConcatenatedJsonWriterTransportAwsTopic] send 262038 
2021-03-19 15:50:19,803 [ConcatenatedJsonWriter] flush 262032 
2021-03-19 15:50:19,803 [ConcatenatedJsonWriterTransportAwsTopic] send 262032 

 - sigh.. still not working
 ^C[ssm-user@ip-10-0-232-10 awscat]$ ./x dynamo:MyTableOnDemand,c=1 arn:aws:sns:us-east-1:343892718819:Dev-Myservice-MyTopic86869434-15ADVC9V4NAHB 2>&1^C

 - fixed: ConcatenatedJsonWriter nasty deadlock bug



performance[2]..
  % ./x 8.json dynamo:OnDemand,wcu=10000 --tranorm="{'id.s':'#{ #uuid() }'}"
this is slow^^ pegging a single core 
  % ./x 8.json /dev/null --transform="{'id.s':' #uuid() }'}"
this ^^ also the same.. pegs a single core 
 SOLN: systemIn needs a threadpool.. its currently running effectively single threaded



performance weirdness on macbook air.. 
 -   986  ./x dynamo:OnDemand /dev/null
seems to "slow down" as time progresses ??

  ALTERNATIVE TO COPYONWRITEARRAYLIST ??
  ALTERNATIVE TO COPYONWRITEARRAYLIST ??
  ALTERNATIVE TO COPYONWRITEARRAYLIST ??



implement some sort of mtu hint ?
 - may not be necessary.. see [#1]



performance..
w/ ObjectMapper:
Fri Mar 19 23:31:02 UTC 2021 Progress{"request":1066633,"success":1066633,"failure":0,"rate":"65848/61953/55182 17148/3429/1143"}
w/o ObjectMapper:
Fri Mar 19 23:33:20 UTC 2021 Progress{"request":1066633,"success":1066633,"failure":0,"rate":"170319/128197/71023 17755/3551/1183"}



counters in/out still wierd never shows in greater than out
 - its because only printed stats in finally block
 - if printing stats at 'request' time then u would see requests vs success/failure difference



 - scale down issue..
rrizun@rrizuns-MacBook-Air dynamocat % ./x dynamo:MyTable dynamo:MyTable
 - slow down because dynamoWriter is .acquire()ing in caller's thread
   - UPDATE: THIS SEEMS TO BE FIXED NOW WITH ASYNC THROTTLE
   - UPDATE: THIS SEEMS TO BE FIXED NOW WITH ASYNC THROTTLE
   - UPDATE: THIS SEEMS TO BE FIXED NOW WITH ASYNC THROTTLE



"random" source
 - rrizun@rrizuns-MacBook-Air dynamocat % awscat in.json,loop=true,limit=1000 dynamo:MyTable --transform="{id:{s:'#{#uuid()}'}}"
 


EVALUATION CONTEXT: STATE AND/OR BEHAVIOR

--spel="e.id.s=uuid()"

--filter="?!?
--expression="?!?"
      <int:transformer input-channel="inChannel"
        output-channel="outChannel"
        expression="payload.toUpperCase() + '- [' + T(System).currentTimeMillis() + ']'"/>
--enrich ?!?
      headers and payload
"By using SpEL for such simple cases, you no longer have to provide a separate class and configure it in the application context.
All you need do is configured the expression attribute with a valid SpEL expression.
The 'payload' and 'headers' variables are bound to the SpEL evaluation context, giving you full access to the incoming message."

#root and #this

--filter="length()>1"
--filter="#root?.length()>1"

--filter="id?.s?.startsWith('foo:')" # safe navigation operator
--apply="id.s"
--apply="#root*2"
--apply="#root*=2" <-- can u do this?
--expression="id.s=#uuid()" <-- this can be done w/getValue.. only for objects??
  UNQUALIFIED REFERENCES ARE RELATIVE TO #THIS
  UNQUALIFIED REFERENCES ARE RELATIVE TO #THIS
  UNQUALIFIED REFERENCES ARE RELATIVE TO #THIS



+ target/awscat-0.0.1-SNAPSHOT.jar -
main[-]
ctor
run
inputPlugin io.github.awscat.SystemInInputPlugin@3d1cfad4
outputPlugin io.github.awscat.SystemOutOutputPluginProvider$$Lambda$381/0x0000000800d112e0@62230c58
input.read().get();111
asdf
1
2
3
java.lang.IllegalStateException: Not a JSON Object: "asdf"
java.lang.IllegalStateException: Not a JSON Object: 1
java.lang.IllegalStateException: Not a JSON Object: 2
java.lang.IllegalStateException: Not a JSON Object: 3
Progress{"in":4,"out":0,"rate":"0/0/0 0/0/0"}
input.read().get();222
rrizun@rrizuns-MacBook-Air dynamocat % 



transform is a little bit weird atm.. inplace transform? vs output=transform(input)
 --transform={"asdf":"#{#input}"}
 --apply={...}



SpEL based filter/transform expressions?
 --filter=id?.s?.startsWith('tax:')
 --action=delete ??
 --transform={Item:"#{#in}"}

 --action={Item:"#{ #this }"} --action={"Item.id.s":"#uuid()"}



JsonElement conversion + JsonElementMapAccessor?



inputPluginProvider: pass arg to canActivate and canActivate



can't cat empty dynamo table ??



- dynamo: dynamically read provisioned capacity units 
 - and periodically (every 25s) setRate


 
--help w/plugin options



independent aws profiles for source and target



 - https://github.com/oracle/graaljs/issues/125

 - THIS BROKE GRAALVM...

                         <groupId>com.google.code.gson</groupId>
                        <artifactId>gson</artifactId>
                </dependency>
+               <dependency>
+                       <groupId>software.amazon.awssdk</groupId>
+                       <artifactId>aws-crt-client</artifactId>
+                       <version>2.16.13-PREVIEW</version>
+               </dependency>
                <dependency>
                        <groupId>software.amazon.awssdk</groupId>
                        <artifactId>dynamodb</artifactId>



 - NEED TO DO THIS ANYWHERE ELSE??

          run(()->{
            return Futures.allAsList(futures);
          }, result->{
            if (!exclusiveStartKeys.get(segment).isEmpty()) //###TODO check for null here?
              doSegment(segment);
          });

 - need to wait for graceful shutdown in receivers, AwsQueueReceiver

 - sqs output plugin

 - fix aws queue input plugin's limit issue

 - call it 'address'
 SYNOPSIS
       socat [options] <address> <address>
       socat -V
       socat -h[h[h]] | -?[?[?]]

